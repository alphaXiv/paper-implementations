2025-12-16 16:42:08,298 INFO    MainThread:181087 [wandb_setup.py:_flush():67] Current SDK version is 0.19.8
2025-12-16 16:42:08,298 INFO    MainThread:181087 [wandb_setup.py:_flush():67] Configure stats pid to 181087
2025-12-16 16:42:08,298 INFO    MainThread:181087 [wandb_setup.py:_flush():67] Loading settings from /home/ubuntu/.config/wandb/settings
2025-12-16 16:42:08,299 INFO    MainThread:181087 [wandb_setup.py:_flush():67] Loading settings from /lambda/nfs/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/wandb/settings
2025-12-16 16:42:08,299 INFO    MainThread:181087 [wandb_setup.py:_flush():67] Loading settings from environment variables
2025-12-16 16:42:08,300 INFO    MainThread:181087 [wandb_init.py:setup_run_log_directory():647] Logging user logs to /lambda/nfs/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/wandb/run-20251216_164208-b5srtjxp/logs/debug.log
2025-12-16 16:42:08,301 INFO    MainThread:181087 [wandb_init.py:setup_run_log_directory():648] Logging internal logs to /lambda/nfs/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/wandb/run-20251216_164208-b5srtjxp/logs/debug-internal.log
2025-12-16 16:42:08,302 INFO    MainThread:181087 [wandb_init.py:init():761] calling init triggers
2025-12-16 16:42:08,302 INFO    MainThread:181087 [wandb_init.py:init():766] wandb.init called with sweep_config: {}
config: {'ref_num_nodes': 1, 'ref_num_gpus_per_node': 4, 'reward_num_nodes': 1, 'reward_num_gpus_per_node': 8, 'colocate_actor_ref': True, 'actor_num_nodes': 1, 'actor_num_gpus_per_node': 4, 'critic_num_nodes': 1, 'critic_num_gpus_per_node': 4, 'colocate_critic_reward': False, 'vllm_num_engines': 4, 'vllm_tensor_parallel_size': 1, 'vllm_sync_backend': 'gloo', 'enable_prefix_caching': False, 'enforce_eager': False, 'eval_steps': 1, 'save_steps': 50, 'logging_steps': 1, 'ckpt_path': '/home/ubuntu/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/outputs/DeepScaleR-Qwen2.5-Math-7B/1216/DeepScaleR-RLVR-math/ckpt', 'max_ckpt_num': 1, 'max_ckpt_mem': 100000000.0, 'load_checkpoint': False, 'local_rank': -1, 'zero_stage': 3, 'gradient_checkpointing': True, 'bf16': True, 'enable_ema': False, 'zpg': 1, 'adam_offload': True, 'actor_init_on_gpu': False, 'flash_attn': True, 'grad_accum_dtype': None, 'disable_trace_cache': False, 'gradient_checkpointing_use_reentrant': False, 'disable_fast_tokenizer': False, 'packing_samples': True, 'load_in_4bit': False, 'lora_rank': 0, 'lora_alpha': 16, 'target_modules': 'all-linear', 'lora_dropout': 0, 'save_path': '/home/ubuntu/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/outputs/DeepScaleR-Qwen2.5-Math-7B/1216/DeepScaleR-RLVR-math/model', 'num_episodes': 200, 'rollout_batch_size': 64, 'micro_rollout_batch_size': 4, 'max_epochs': 1, 'prompt_max_len': 1024, 'generate_max_len': 3072, 'max_len': None, 'max_samples': 400000, 'max_norm': 1.0, 'l2': 0.0, 'ptx_coef': 0.05, 'eps_clip': 0.2, 'value_clip': 0.2, 'lambd': 1.0, 'gamma': 1.0, 'micro_train_batch_size': 4, 'train_batch_size': 128, 'normalize_reward': True, 'top_p': 1.0, 'temperature': 1.0, 'seed': 42, 'freezing_actor_steps': -1, 'n_samples_per_prompt': 16, 'save_value_network': False, 'use_kl_loss': True, 'use_entropy_loss': False, 'use_policy_loss_wo_old_log_probs': False, 'entropy_coef': 0.0, 'use_online_sft': False, 'actor_learning_rate': 5e-07, 'actor_scheduler': 'constant', 'critic_learning_rate': 9e-06, 'lr_warmup_ratio': 0.0, 'kl_target': None, 'init_kl_coef': 0.0, 'use_kl_estimator_k3': False, 'aux_loss_coef': 0, 'adam_betas': (0.9, 0.95), 'reward_clip_range': (-10, 10), 'advantage_estimator': 'group_norm', 'training_mode': 'rl', 'pretrain': 'Qwen/Qwen2.5-Math-7B', 'reward_pretrain': None, 'remote_rm_url': None, 'critic_pretrain': None, 'value_head_prefix': 'score', 'ref_reward_offload': False, 'verify_task': 'math', 'verify_task_eval': 'math', 'filter_samples_by_reward': False, 'prompt_data': 'json@/home/ubuntu/texas-sandbox/paper-implementations/spurious_rewards/src/spurious_rewards/code/data/DeepScaleR', 'prompt_data_probs': '1.0', 'prompt_split': 'train', 'pretrain_data': None, 'pretrain_data_probs': '1.0', 'pretrain_split': 'train', 'stop_string': None, 'input_key': 'prompt', 'label_key': 'answer', 'output_key': 'output', 'add_think_token': 0, 'add_prompt_suffix': None, 'input_template': None, 'apply_chat_template': True, 'extra_eval_task': None, 'extra_eval_task_fast': 'test,AIME2025-TTT@8,AIME-TTT@8,AMC-TTT@8,AMC-TTT@1,MATH-TTT@1', 'extra_eval_task_fast_supress_orig_eval': True, 'extra_eval_trajectory': None, 'extra_eval_trajectory_steps': None, 'extra_eval_trajectory_temperature': 1, 'use_golden_response': False, 'n_votes_per_prompt': 64, 'filter_samples_by_majority_ratio': None, 'eval_temperature': 0.0, 'eval_temperature_at_k': 0.6, 'eval_top_p': 1.0, 'use_wandb': '1', 'wandb_org': None, 'wandb_group': None, 'wandb_project': 'SpuriousRewardRLVR', 'wandb_run_name': '1216-qwen2.5_math_7b-DeepScaleR-RLVR-math-lr5e-7-kl0.00', 'use_tensorboard': None, 'perf': False, '_wandb': {}}
2025-12-16 16:42:08,303 INFO    MainThread:181087 [wandb_init.py:init():784] starting backend
2025-12-16 16:42:08,303 INFO    MainThread:181087 [wandb_init.py:init():788] sending inform_init request
2025-12-16 16:42:08,320 INFO    MainThread:181087 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-12-16 16:42:08,320 INFO    MainThread:181087 [wandb_init.py:init():798] backend started and connected
2025-12-16 16:42:08,321 INFO    MainThread:181087 [wandb_init.py:init():891] updated telemetry
2025-12-16 16:42:08,338 INFO    MainThread:181087 [wandb_init.py:init():915] communicating run to backend with 240.0 second timeout
2025-12-16 16:42:08,779 INFO    MainThread:181087 [wandb_init.py:init():990] starting run threads in backend
2025-12-16 16:42:09,161 INFO    MainThread:181087 [wandb_run.py:_console_start():2375] atexit reg
2025-12-16 16:42:09,161 INFO    MainThread:181087 [wandb_run.py:_redirect():2227] redirect: wrap_raw
2025-12-16 16:42:09,162 INFO    MainThread:181087 [wandb_run.py:_redirect():2292] Wrapping output streams.
2025-12-16 16:42:09,162 INFO    MainThread:181087 [wandb_run.py:_redirect():2315] Redirects installed.
2025-12-16 16:42:09,183 INFO    MainThread:181087 [wandb_init.py:init():1032] run started, returning control to user process
